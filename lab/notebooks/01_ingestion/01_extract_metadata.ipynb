{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../src')\n",
    "\n",
    "from baml_client.async_client import b\n",
    "from utils import read_raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_dataset_path = \"../../../data/Wikipedia.json\"\n",
    "df = read_raw_dataset(kaggle_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = \"../../data/metadata\"\n",
    "os.makedirs(metadata_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_batch(batch):\n",
    "    to_sleep = random.randint(1, 60)\n",
    "    print(f\"Sleeping for {to_sleep} seconds\")\n",
    "    await asyncio.sleep(to_sleep)\n",
    "\n",
    "    for _, row in batch.iterrows():\n",
    "        filename = f'{metadata_path}/{row._id}.parquet'\n",
    "        if os.path.exists(filename):\n",
    "            print(f\"Skipping {filename}\")\n",
    "            continue\n",
    "\n",
    "        article = row['article']\n",
    "        metadata = await b.ExtractArticleMetadata(article)\n",
    "        entities = [\n",
    "            {\"name\": e.name, \"type\": e.type.name}\n",
    "            for e in metadata.entities\n",
    "        ]\n",
    "\n",
    "        df_row = row.to_frame().T.assign(\n",
    "            entities=[entities],\n",
    "            triples=[metadata.triples],\n",
    "        )\n",
    "\n",
    "        df_row = df_row[['_id', 'entities', 'triples']]\n",
    "        df_row.to_parquet(filename, index=False)\n",
    "\n",
    "        await asyncio.sleep(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbatch = 100\n",
    "batch_size = len(df) // nbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [\n",
    "    df[i:i + batch_size]\n",
    "    for i in range(0, len(df), batch_size)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await asyncio.gather(*[\n",
    "    process_batch(batch)\n",
    "    for batch in batches\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
